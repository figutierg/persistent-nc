{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-27T00:11:16.500667Z",
     "start_time": "2025-08-27T00:11:07.852064Z"
    }
   },
   "source": [
    "from models.pretrained_model_transfer import pretrained_model\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tllib.ranking.logme import log_maximum_evidence as LogME\n",
    "import pprint\n",
    "from datasets import load_dataset, DownloadConfig\n",
    "\n",
    "import pickle\n",
    "from torchvision.models import (\n",
    "    MobileNet_V2_Weights, MNASNet1_0_Weights, DenseNet121_Weights,\n",
    "    DenseNet169_Weights, DenseNet201_Weights, ResNet34_Weights,\n",
    "    ResNet50_Weights, ResNet101_Weights, ResNet152_Weights,\n",
    "    GoogLeNet_Weights, Inception_V3_Weights\n",
    ")\n",
    "import numpy as np\n",
    "from gudhi.rips_complex import RipsComplex"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:37.208098Z",
     "start_time": "2025-07-31T07:07:37.197191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_persistence_diagram(features: np.ndarray, max_edge_length: float = 100):\n",
    "    \"\"\"\n",
    "    Takes feature embeddings and computes the H0 persistence diagram.\n",
    "    This function encapsulates the Gudhi TDA calculation.\n",
    "    \"\"\"\n",
    "    if features.shape[0] == 0:\n",
    "        print(\"Warning: Input features for PD are empty.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        print(\"Computing Persistence Diagram...\")\n",
    "        features_contiguous = np.ascontiguousarray(features, dtype=np.float64)\n",
    "        rips_complex = RipsComplex(points=features_contiguous, max_edge_length=max_edge_length)\n",
    "        simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "        diag = simplex_tree.persistence()\n",
    "        h0_diag = [(pair[1][0], pair[1][1]) for pair in diag if pair[0] == 0 and pair[1][1] != float('inf')]\n",
    "        print(f\"Computed H0 persistence diagram with {len(h0_diag)} finite bars.\")\n",
    "        return h0_diag\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Gudhi computation: {e}\")\n",
    "        return None\n",
    "\n",
    "def intercd(features: np.ndarray, labels: np.ndarray, pd_max_edge_length: float = 50):\n",
    "    \"\"\"\n",
    "    Computes the Inter-level Persistence Score from feature embeddings.\n",
    "\n",
    "    This score is the average persistence of the k-1 most persistent topological\n",
    "    features (connected components), where k is the number of unique classes.\n",
    "\n",
    "    Args:\n",
    "        features (np.ndarray): The feature embeddings from the model.\n",
    "        labels (np.ndarray): The ground-truth labels for the features.\n",
    "        pd_max_edge_length (float): Maximum edge length for the Rips complex.\n",
    "\n",
    "    Returns:\n",
    "        The Inter-level Persistence score as a float. Returns 0.0 if the\n",
    "        computation cannot be completed.\n",
    "    \"\"\"\n",
    "    # 1. Basic check for valid input\n",
    "    if features.shape[0] == 0:\n",
    "        print(\"Warning: Input 'features' is empty. Skipping InterCD calculation.\")\n",
    "        return 0.0\n",
    "\n",
    "    # 2. Compute the H0 persistence diagram using Gudhi\n",
    "    h0_diag = None  # Initialize to None\n",
    "    print(\"Computing Persistence Diagram...\")\n",
    "    try:\n",
    "        # Gudhi requires a C-contiguous array for performance\n",
    "        features_contiguous = np.ascontiguousarray(features, dtype=np.float64)\n",
    "\n",
    "        rips_complex = RipsComplex(points=features_contiguous, max_edge_length=pd_max_edge_length)\n",
    "        simplex_tree = rips_complex.create_simplex_tree(max_dimension=1)\n",
    "        diag = simplex_tree.persistence()\n",
    "\n",
    "        # Filter for H0 (dimension 0) features and pairs with a finite death time\n",
    "        h0_diag = [(pair[1][0], pair[1][1]) for pair in diag if pair[0] == 0 and pair[1][1] != float('inf')]\n",
    "        print(f\"Computed H0 persistence diagram with {len(h0_diag)} finite bars.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Gudhi computation: {e}\")\n",
    "        # h0_diag will remain None if an error occurs\n",
    "\n",
    "    # 3. Check if the diagram was successfully computed\n",
    "    if h0_diag is None or not h0_diag:\n",
    "        print(\"Warning: Persistence diagram could not be computed or is empty.\")\n",
    "        return 0.0  # Return a default score of 0\n",
    "\n",
    "    # 4. Calculate the score from the diagram\n",
    "    k = len(np.unique(labels))\n",
    "    if k <= 1:\n",
    "        print(\"Warning: Cannot compute score with only one class (k=1).\")\n",
    "        return 0.0\n",
    "\n",
    "    # Get a sorted list of all persistence values (death_time - birth_time)\n",
    "    # For H0, birth_time is always 0, so this is just a list of death_times.\n",
    "    persistences = sorted([death - birth for birth, death in h0_diag], reverse=True)\n",
    "\n",
    "    # 5. Check if we have enough persistence bars for the calculation\n",
    "    if len(persistences) < k - 1:\n",
    "        print(f\"Warning: Not enough persistence bars ({len(persistences)}) to compute score for k={k} classes. Returning 0.\")\n",
    "        return 0.0\n",
    "\n",
    "    # The score is the average of the k-1 most persistent features\n",
    "    persist_inter = np.array(persistences[:k - 1])\n",
    "    score = np.mean(persist_inter)\n",
    "\n",
    "    return score"
   ],
   "id": "8074468909fc9625",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:37.255737Z",
     "start_time": "2025-07-31T07:07:37.247291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def score_model(configs, score_loader, device):\n",
    "    print(f'Calc Transferabilities of {configs.model} on {configs.dataset}')\n",
    "\n",
    "    if configs.model == 'inception_v3':\n",
    "        model = models.__dict__[configs.model](pretrained=True, aux_logits=False).cuda()\n",
    "    else:\n",
    "        model = models.__dict__[configs.model](pretrained=True).cuda()\n",
    "\n",
    "    # different models has different linear projection names\n",
    "    if configs.model in ['mobilenet_v2', 'mnasnet1_0']:\n",
    "        fc_layer = model.classifier[-1]\n",
    "    elif configs.model in ['densenet121', 'densenet169', 'densenet201']:\n",
    "        fc_layer = model.classifier\n",
    "    elif configs.model in ['resnet34', 'resnet50', 'resnet101', 'resnet152', 'googlenet', 'inception_v3']:\n",
    "        fc_layer = model.fc\n",
    "    else:\n",
    "        # try your customized model\n",
    "        raise NotImplementedError\n",
    "\n",
    "    print('Conducting features extraction...')\n",
    "    model = pretrained_model(model, fc_layer)\n",
    "    features, outputs, targets = forward_pass_with_wrapper(score_loader, model, device)\n",
    "    # predictions = F.softmax(outputs)\n",
    "\n",
    "    print('Conducting transferability calculation...')\n",
    "    logme_score = LogME(features.numpy(), targets.numpy(), regression=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sample_size = 2048\n",
    "    num_samples = features.shape[0]\n",
    "\n",
    "    # Check if the dataset is large enough to sample from\n",
    "    if num_samples > sample_size:\n",
    "        print(f\"Taking a random sample of {sample_size} from {num_samples} total samples for intercd score.\")\n",
    "\n",
    "        # 1. Generate a random permutation of indices from 0 to num_samples-1\n",
    "        indices = torch.randperm(num_samples)\n",
    "\n",
    "        # 2. Select the first `sample_size` indices from the random permutation\n",
    "        sample_indices = indices[:sample_size]\n",
    "\n",
    "        # 3. Use these indices to select a subset of features and targets\n",
    "        sampled_features = features[sample_indices]\n",
    "        sampled_targets = targets[sample_indices]\n",
    "    else:\n",
    "        # If the dataset is smaller than the desired sample size, just use all of it\n",
    "        print(f\"Dataset size ({num_samples}) is smaller than sample size ({sample_size}), using all data for intercd score.\")\n",
    "        sampled_features = features\n",
    "        sampled_targets = targets\n",
    "    # --- END: New code for random sampling ---\n",
    "\n",
    "    # Calculate intercd_score on the (potentially smaller) sampled dataset\n",
    "    intercd_score = intercd(sampled_features.numpy(), sampled_targets.numpy())\n",
    "    print(f'Intercd score: {intercd_score}')\n",
    "\n",
    "    # save calculated bayesian weight\n",
    "#    torch.save(logme.ms, f'logme_{configs.dataset}/weight_{configs.model}.pth')\n",
    "\n",
    "    print(f'LogME of {configs.model}: {logme_score}\\n')\n",
    "    return logme_score\n",
    "\n"
   ],
   "id": "365e8bdd3043b960",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:37.358861Z",
     "start_time": "2025-07-31T07:07:37.328736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "models_hub = ['mobilenet_v2', 'mnasnet1_0', 'densenet121', 'densenet169', 'densenet201',\n",
    "              'resnet34', 'resnet50', 'resnet101', 'resnet152', 'googlenet', 'inception_v3']\n",
    "#models_hub = ['mobilenet_v2']\n",
    "\n",
    "def collate_fn_skip_corrupt(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "\n",
    "    if not batch:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "\n",
    "    images, labels = zip(*batch)\n",
    "\n",
    "    # The 'labels' tuple now correctly contains integers.\n",
    "    # The [int(lbl) for lbl in labels] line is no longer needed.\n",
    "\n",
    "    images_batch = torch.stack(images, 0)\n",
    "    labels_batch = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return images_batch, labels_batch\n",
    "\n",
    "class HuggingFaceDatasetWrapper(Dataset):\n",
    "    \"\"\"\n",
    "    The updated, more general wrapper.\n",
    "    \"\"\"\n",
    "    def __init__(self, hf_dataset, transform=None, label_map=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.hf_dataset[idx]\n",
    "            image = item['image']\n",
    "            raw_label = item['label']\n",
    "\n",
    "            # =================== THE FIX ===================\n",
    "            # Use the label map only if one was provided\n",
    "            if self.label_map:\n",
    "                # This block runs for Birdsnap\n",
    "                label = self.label_map[raw_label]\n",
    "            else:\n",
    "                # This block runs for SUN397\n",
    "                label = raw_label\n",
    "            # ===============================================\n",
    "\n",
    "            # Minor bug fix: Convert to RGB *before* transforming\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "        except OSError as e:\n",
    "            print(f\"Warning: Skipping corrupt image at index {idx}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class CustomSUN397Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the manually downloaded SUN397 data.\n",
    "    It reads a specific split file (e.g., Training_01.txt) to load data.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_root_dir, split_file, class_name_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_dir (string): Path to the SUN397 directory with all the images.\n",
    "            split_file (string): Path to the text file defining the data split (e.g., Training_01.txt).\n",
    "            class_name_file (string): Path to the ClassName.txt file.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_root_dir = image_root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 1. Create a mapping from class path (e.g., '/a/abbey') to an integer index (e.g., 0)\n",
    "        with open(class_name_file, 'r') as f:\n",
    "            # Reads '/a/abbey\\n' and maps it to its line number (index)\n",
    "            self.class_to_idx = {line.strip(): i for i, line in enumerate(f)}\n",
    "\n",
    "        # 2. Read the image paths and create corresponding labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        with open(split_file, 'r') as f:\n",
    "            for line in f:\n",
    "                relative_path = line.strip()\n",
    "                self.image_paths.append(relative_path)\n",
    "\n",
    "                # Extract class path from image path (e.g., '/a/abbey' from '/a/abbey/sun_...jpg')\n",
    "                class_path = os.path.dirname(relative_path)\n",
    "                self.labels.append(self.class_to_idx[class_path])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Construct the full image path\n",
    "        # We use lstrip('/') to remove the leading '/' so os.path.join works correctly\n",
    "        img_path = os.path.join(self.image_root_dir, self.image_paths[idx].lstrip('/'))\n",
    "\n",
    "        # Load the image and ensure it's in RGB format\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Get the integer label\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transformations if they exist\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_dataset(dataset_name: str, transform: transforms.Compose, data_path: str = 'data'):\n",
    "    \"\"\"\n",
    "    Loads or downloads the specified dataset.\n",
    "\n",
    "    :param dataset_name: The name of the dataset to load.\n",
    "    :param transform: The torchvision transforms to apply to the dataset.\n",
    "    :param data_path: The root directory to save downloaded datasets.\n",
    "    :return: A torch.utils.data.Dataset object.\n",
    "    \"\"\"\n",
    "    # Create the root data directory if it doesn't exist\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    name = dataset_name.lower()\n",
    "\n",
    "    # --- Handle ImageNet with the hardcoded relative path ---\n",
    "    if name == 'imagenet':\n",
    "        print(\"Using pre-downloaded ImageNet from relative path...\")\n",
    "        # Go up 5 levels from /home/alpaca/Tesis/networks/resultsagg/analysis/transfer_benchmarks/\n",
    "        # to /home/alpaca/, then into datasets/imagenet/train\n",
    "        # os.path.join is used for cross-platform compatibility.\n",
    "        imagenet_path = os.path.join('../../../../../datasets/imagenet', 'train')\n",
    "        if not os.path.isdir(imagenet_path):\n",
    "            raise FileNotFoundError(f\"ImageNet path not found at relative location: {imagenet_path}\")\n",
    "        return datasets.ImageFolder(root=imagenet_path, transform=transform)\n",
    "\n",
    "    # --- Handle standard torchvision datasets ---\n",
    "    # The `download=True` flag will automatically download the data if not found in `root`.\n",
    "    elif name == 'aircraft':\n",
    "        return datasets.FGVCAircraft(root=data_path, split='train', transform=transform, download=True)\n",
    "    elif name == 'caltech101':\n",
    "        print(\"Loading Caltech-101 from local ImageFolder...\")\n",
    "\n",
    "        # Define the path directly to the folder containing the class subdirectories\n",
    "        image_path = os.path.join('../../../../../datasets', 'caltech-101', '101_ObjectCategories')\n",
    "\n",
    "        # ImageFolder will automatically find all class folders and their images\n",
    "        return datasets.ImageFolder(root=image_path, transform=transform)\n",
    "\n",
    "    elif name == 'cifar10':\n",
    "        return datasets.CIFAR10(root=data_path, train=True, transform=transform, download=True)\n",
    "    elif name == 'cifar100':\n",
    "        return datasets.CIFAR100(root=data_path, train=True, transform=transform, download=True)\n",
    "    elif name == 'dtd':\n",
    "        return datasets.DTD(root=data_path, split='train', transform=transform, download=True)\n",
    "    elif name == 'oxfordiiitpets':\n",
    "        return datasets.OxfordIIITPet(root=data_path, split='trainval', transform=transform, download=True)\n",
    "\n",
    "    elif name == 'stanfordcars':\n",
    "        print(\"Loading Stanford Cars from local ImageFolder...\")\n",
    "\n",
    "        # Define the path directly to your training data folder\n",
    "        train_path = os.path.join('../../../../../datasets', 'stanford_cars', 'train')\n",
    "\n",
    "        # ImageFolder handles everything automatically!\n",
    "        return datasets.ImageFolder(root=train_path, transform=transform)\n",
    "\n",
    "    # ... (other cases) .\n",
    "    elif name == 'sun397':\n",
    "        print(\"Loading SUN397 from local custom path...\")\n",
    "\n",
    "        # Define the paths based on your file structure\n",
    "        base_dir = \"../../../../../datasets/SUN_dataset/data\"\n",
    "        image_root_dir = os.path.join(base_dir, \"SUN397\")\n",
    "        class_name_file = os.path.join(base_dir, \"ClassName.txt\")\n",
    "\n",
    "        # Select which split to use. Here we use the first training split.\n",
    "        # You can easily change this to \"Testing_01.txt\" to load the test set.\n",
    "        split_file = os.path.join(base_dir, \"Training_01.txt\")\n",
    "\n",
    "        # Instantiate and return your custom dataset\n",
    "        return CustomSUN397Dataset(\n",
    "            image_root_dir=image_root_dir,\n",
    "            split_file=split_file,\n",
    "            class_name_file=class_name_file,\n",
    "            transform=transform\n",
    "        )\n",
    "    elif name == 'birdsnap':\n",
    "        print(\"Loading 'sasha/birdsnap' and creating label map...\")\n",
    "        # Load the training split\n",
    "\n",
    "        download_config = DownloadConfig( # Set timeout to 300 seconds (5 minutes)\n",
    "            max_retries=5,  # Allow up to 5 retries on failure\n",
    "        )\n",
    "        hf_train_dataset = load_dataset(\"sasha/birdsnap\", split='train')\n",
    "\n",
    "        # =================== THE FIX ===================\n",
    "        # Get all unique string labels from the dataset\n",
    "        all_string_labels = sorted(hf_train_dataset.unique(\"label\"))\n",
    "        # Create the mapping from string name to integer index\n",
    "        label_map = {name: i for i, name in enumerate(all_string_labels)}\n",
    "        print(f\"Created map for {len(label_map)} unique classes.\")\n",
    "        # ===============================================\n",
    "\n",
    "        # Pass the dataset AND the new map to the wrapper\n",
    "        return HuggingFaceDatasetWrapper(\n",
    "            hf_dataset=hf_train_dataset,\n",
    "            transform=transform,\n",
    "            label_map=label_map\n",
    "        )\n",
    "        # Use the wrapper to make it compatible with PyTorch's DataLoader\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset '{dataset_name}' is not supported.\")\n",
    "\n",
    "def forward_pass_with_wrapper(score_loader, wrapped_model, device = 'cuda'):\n",
    "    \"\"\"\n",
    "    A forward pass on the target dataset using the pretrained_model wrapper.\n",
    "\n",
    "    :params score_loader: The dataloader for scoring transferability.\n",
    "    :params wrapped_model: The pretrained_model wrapper instance, which handles hook management internally.\n",
    "    :returns:\n",
    "        features: Extracted features (input to the final linear layer).\n",
    "        outputs: The final outputs of the model.\n",
    "        targets: Ground-truth labels of the dataset.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    # No need to define a local hook function or manually register/remove it.\n",
    "    # The wrapper class handles this automatically.\n",
    "\n",
    "    wrapped_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(score_loader):\n",
    "                        # --- START DEBUG ---\n",
    "            # Print the type and value of target for each batch\n",
    "           # print(f\"Batch {batch_idx}: type(target) is {type(target)}\")\n",
    "            # --- END DEBUG ---\n",
    "            if data.nelement() == 0:\n",
    "                print('git gut, continue, something with 0 elements, not cool')\n",
    "                continue\n",
    "\n",
    "            # Move data to the same device as the model\n",
    "            data = data.to(wrapped_model.device)\n",
    "            targets.append(target)\n",
    "\n",
    "            # 1. Run the forward pass to get the final model outputs.\n",
    "            # As a side effect, the model's internal hook will automatically\n",
    "            # capture the input to the final layer.\n",
    "            batch_outputs = wrapped_model(data)\n",
    "\n",
    "            # 2. Access the feature captured by the hook.\n",
    "            # The `_captured_feature` attribute is updated during the forward pass.\n",
    "            batch_features = wrapped_model._captured_feature\n",
    "\n",
    "            # Append the results for the current batch\n",
    "            features.append(batch_features.cpu())\n",
    "            outputs.append(batch_outputs.cpu())\n",
    "\n",
    "    # Concatenate all batch results into single tensors\n",
    "    features = torch.cat(features)\n",
    "    outputs = torch.cat(outputs)\n",
    "    targets = torch.cat(targets)\n",
    "\n",
    "    return features, outputs, targets"
   ],
   "id": "5c854dda26b95b81",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:37.379418Z",
     "start_time": "2025-07-31T07:07:37.376248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This class replaces the get_configs() function and argparse\n",
    "class NotebookConfigs:\n",
    "    \"\"\"\n",
    "    A simple class to hold the configuration parameters for the notebook.\n",
    "    This mimics the behavior of the object returned by parser.parse_args().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # --- Execution Parameters ---\n",
    "        self.gpu = 'cuda'\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 0\n",
    "\n",
    "        # --- Dataset to be analyzed ---\n",
    "        # YOU CAN CHANGE THIS VALUE IN YOUR NOTEBOOK\n",
    "        # Options: 'aircraft', 'caltech101', 'cifar10', 'cifar100',\n",
    "        #          'dtd', 'oxfordiiitpets', 'stanfordcars', 'sun397', 'imagenet'\n",
    "        self.dataset = None\n",
    "\n",
    "        # The 'model' attribute will be set inside the loop in main()\n",
    "        self.model = None\n",
    "\n",
    "# --- In a notebook cell, you would create the configs object like this ---\n",
    "configs = NotebookConfigs()\n"
   ],
   "id": "4bdff1c035cac4f2",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:37.464569Z",
     "start_time": "2025-07-31T07:07:37.444855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_and_save(configs, score_loader, device):\n",
    "    \"\"\"\n",
    "    This function replaces the old 'score_model'. It runs the forward pass,\n",
    "    pre-computes necessary items, and saves everything to disk.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting extraction for model: {configs.model} on dataset: {configs.dataset} ---\")\n",
    "\n",
    "    # =====================================================================\n",
    "    # --- THIS IS THE MODIFIED SECTION ---\n",
    "    # 1. Define the mapping from model name string to the correct V1 weights\n",
    "    weights_mapping = {\n",
    "        'mobilenet_v2': MobileNet_V2_Weights.IMAGENET1K_V1,\n",
    "        'mnasnet1_0': MNASNet1_0_Weights.IMAGENET1K_V1,\n",
    "        'densenet121': DenseNet121_Weights.IMAGENET1K_V1,\n",
    "        'densenet169': DenseNet169_Weights.IMAGENET1K_V1,\n",
    "        'densenet201': DenseNet201_Weights.IMAGENET1K_V1,\n",
    "        'resnet34': ResNet34_Weights.IMAGENET1K_V1,\n",
    "        'resnet50': ResNet50_Weights.IMAGENET1K_V1,\n",
    "        'resnet101': ResNet101_Weights.IMAGENET1K_V1,\n",
    "        'resnet152': ResNet152_Weights.IMAGENET1K_V1,\n",
    "        'googlenet': GoogLeNet_Weights.IMAGENET1K_V1,\n",
    "        'inception_v3': Inception_V3_Weights.IMAGENET1K_V1\n",
    "    }\n",
    "\n",
    "    # 2. Load Model using the explicit V1 weights\n",
    "    weights = weights_mapping[configs.model]\n",
    "    if configs.model == 'inception_v3':\n",
    "        model = models.__dict__[configs.model](weights=weights, aux_logits=True).to(device)\n",
    "    else:\n",
    "        model = models.__dict__[configs.model](weights=weights).to(device)\n",
    "    # --- END OF MODIFIED SECTION ---\n",
    "    # =====================================================================\n",
    "\n",
    "\n",
    "    # --- Find fc_layer (logic remains the same) ---\n",
    "    if configs.model in ['mobilenet_v2', 'mnasnet1_0']:\n",
    "        fc_layer = model.classifier[-1]\n",
    "    elif 'densenet' in configs.model:\n",
    "        fc_layer = model.classifier\n",
    "    elif 'resnet' in configs.model or configs.model in ['googlenet', 'inception_v3']:\n",
    "        fc_layer = model.fc\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Classifier layer logic not defined for model: {configs.model}\")\n",
    "\n",
    "\n",
    "    # 2. Extract Features, Outputs, and Targets\n",
    "    print('Conducting features extraction...')\n",
    "    wrapped_model = pretrained_model(model, fc_layer, device=device)\n",
    "    print('Model instantiated, intializing forward pass')\n",
    "    features, outputs, targets = forward_pass_with_wrapper(score_loader, wrapped_model)\n",
    "    print('Forward pass successful')\n",
    "    # 3. Pre-compute anything else needed for scoring\n",
    "    #    - Predicted labels for NCE score\n",
    "    predicted_labels = torch.argmax(outputs, dim=1)\n",
    "    #    - Persistence diagram for InterCD score (using a sub-sample)\n",
    "    print('subsampling for persistent diagram')\n",
    "    sample_size = 4096\n",
    "    if features.shape[0] > sample_size:\n",
    "        indices = torch.randperm(features.shape[0])[:sample_size]\n",
    "        sampled_features_for_pd = features[indices]\n",
    "    else:\n",
    "        sampled_features_for_pd = features\n",
    "    print('computing persistent diagram')\n",
    "    persistence_diagram = compute_persistence_diagram(sampled_features_for_pd.numpy())\n",
    "\n",
    "    # 4. Define Save Directory and Save Everything\n",
    "    save_dir = os.path.join('extraction_results', configs.dataset, configs.model)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Saving results to: {save_dir}\")\n",
    "\n",
    "    # Move to CPU before saving to ensure portability\n",
    "    torch.save(features.cpu(), os.path.join(save_dir, 'features.pt'))\n",
    "    torch.save(outputs.cpu(), os.path.join(save_dir, 'outputs.pt'))\n",
    "    torch.save(targets.cpu(), os.path.join(save_dir, 'targets.pt'))\n",
    "    torch.save(predicted_labels.cpu(), os.path.join(save_dir, 'predicted_labels.pt'))\n",
    "\n",
    "    if persistence_diagram is not None:\n",
    "        with open(os.path.join(save_dir, 'persistence_diagram.pkl'), 'wb') as f:\n",
    "            pickle.dump(persistence_diagram, f)\n",
    "\n",
    "    print(f\"--- Finished extraction for model: {configs.model} ---\")\n",
    "\n",
    "def main_extraction():\n",
    "   # configs = NotebookConfigs() # Assuming you have your NotebookConfigs class\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Loop through your models\n",
    "    for model_name in models_hub:\n",
    "        configs.model = model_name\n",
    "        if model_name == 'inception_v3':\n",
    "            transform = transforms.Compose([transforms.Resize((299, 299)), transforms.ToTensor(), normalize])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), normalize])\n",
    "\n",
    "        # --- Dataset Loading and Sub-sampling Logic ---\n",
    "        print('getting dataset')\n",
    "        full_dataset = get_dataset(dataset_name=configs.dataset, transform=transform)\n",
    "        print('getting model')\n",
    "        # Using a smaller sample size for demonstration\n",
    "        num_samples_to_use = 250000\n",
    "        if configs.dataset.lower() == 'imagenet' and len(full_dataset) > num_samples_to_use:\n",
    "            # Using stratified sampling\n",
    "            print('getting targets')\n",
    "            targets = full_dataset.targets\n",
    "            indices = np.arange(len(full_dataset))\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            print('splitting dataset into training and test sets')\n",
    "            subset_indices, _ = train_test_split(indices, train_size=num_samples_to_use, stratify=targets, random_state=42)\n",
    "            score_dataset = torch.utils.data.Subset(full_dataset, subset_indices)\n",
    "\n",
    "        else:\n",
    "            score_dataset = full_dataset\n",
    "\n",
    "        print(f\"Initializing DataLoader with {len(score_dataset)} samples.\")\n",
    "        score_loader = DataLoader(score_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                  num_workers=0, pin_memory=True, collate_fn=collate_fn_skip_corrupt) # Use num_workers=0 to avoid issues\n",
    "\n",
    "        # Run the extraction and saving process\n",
    "        print(f\"Initializing model: {configs.model} on dataset: {configs.dataset} ---\")\n",
    "        extract_and_save(configs, score_loader, device)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # You can then easily check the values\n",
    "    print(f\"Running analysis on dataset: {configs.dataset}\")\n",
    "    print(f\"Using batch size: {configs.batch_size}\")\n",
    "\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    if not os.path.isdir(f'logme_{configs.dataset}'):\n",
    "        os.mkdir(f'logme_{configs.dataset}')\n",
    "    score_dict = {}\n",
    "    for model in models_hub:\n",
    "        configs.model = model\n",
    "        if model == 'inception_v3':  # inception_v3 is pretrained on 299x299 images\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((299, 299)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([  # other models are pretrained on 224x224 images\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "            #############################ACA VER TEMA DE DATA####################################\n",
    "\n",
    "        print('getting dataset')\n",
    "        full_score_dataset = get_dataset(dataset_name=configs.dataset, transform=transform)\n",
    "        print('getting datset success')\n",
    "        # Define the desired number of samples\n",
    "        num_samples_to_use = 250000\n",
    "\n",
    "        # --- Sub-sampling Logic ---\n",
    "        # Check if the current dataset is 'imagenet' and if it's larger than our target sample size\n",
    "        if configs.dataset.lower() == 'imagenet' and len(full_score_dataset) > num_samples_to_use:\n",
    "            print(f\"Dataset is ImageNet. Sub-sampling from {len(full_score_dataset)} to {num_samples_to_use} images.\")\n",
    "\n",
    "            # 1. Generate a random permutation of indices for the full dataset\n",
    "            indices = torch.randperm(len(full_score_dataset))\n",
    "\n",
    "            # 2. Select the first N indices from the shuffled list\n",
    "            subset_indices = indices[:num_samples_to_use]\n",
    "\n",
    "            # 3. Create a Subset wrapper using the original dataset and the random indices\n",
    "            score_dataset = torch.utils.data.Subset(full_score_dataset, subset_indices)\n",
    "\n",
    "        else:\n",
    "            # If the dataset is not ImageNet, or if it's smaller than the desired sample size,\n",
    "            # we use the original, full dataset.\n",
    "            score_dataset = full_score_dataset\n",
    "        # --- End of Logic ---\n",
    "\n",
    "\n",
    "        # Initialize the DataLoader with the (potentially smaller) dataset\n",
    "        print(f\"Initializing DataLoader with {len(score_dataset)} samples.\")\n",
    "        score_loader = DataLoader(score_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                  num_workers=configs.num_workers, pin_memory=True)\n",
    "\n",
    "        # or try your customized dataset\n",
    "        score_loader = DataLoader(score_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                  num_workers=configs.num_workers, pin_memory=True)\n",
    "        score_dict[model] = score_model(configs, score_loader, device)\n",
    "    results = sorted(score_dict.items(), key=lambda i: i[1], reverse=True)\n",
    "    torch.save(score_dict, f'logme_{configs.dataset}/results.pth')\n",
    "    print(f'Models ranking on {configs.dataset}: ')\n",
    "    pprint.pprint(results)\n"
   ],
   "id": "cced3a45049a6be0",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T20:38:06.951108Z",
     "start_time": "2025-07-31T08:15:10.966363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "datasets_to_run = [\n",
    "    'aircraft',\n",
    "    'cifar10',\n",
    "    'cifar100',\n",
    "    'dtd',\n",
    "    'oxfordiiitpets',\n",
    "    'sun397',\n",
    "    'stanfordcars',\n",
    "    'caltech101',\n",
    "    'birdsnap',\n",
    "    'imagenet'\n",
    "]\n",
    "\n",
    "\n",
    "#stanfordcars and caltech101 birdsnap, SUN missing\n",
    "\n",
    "for current_dataset in datasets_to_run:\n",
    "    configs.dataset = current_dataset\n",
    "    main_extraction()"
   ],
   "id": "4c4ab7a9b7a7449b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f3fdd7463d9441db8c7fedfc5473063"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e662db6aeaa043d196a1c3e74ff6d7b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: mobilenet_v2 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: mobilenet_v2 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/mobilenet_v2\n",
      "--- Finished extraction for model: mobilenet_v2 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfd93a9d25fa4246ada65e285c62295b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2e2210e736246ac90ee4369f6f14335"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: mnasnet1_0 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: mnasnet1_0 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/mnasnet1_0\n",
      "--- Finished extraction for model: mnasnet1_0 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8eec53e90ab748ec91686ee910785722"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d591bedf3fab469cbf04bdb9cf591cb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: densenet121 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: densenet121 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/densenet121\n",
      "--- Finished extraction for model: densenet121 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab773700a7b24d4eb6cadf34e70dfc41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9545baa0842466a867e7c3213e2b373"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: densenet169 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: densenet169 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/densenet169\n",
      "--- Finished extraction for model: densenet169 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05a7236fac074260830db053faed8ad5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c1e16a59c3844c793f0d1b546874bf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: densenet201 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: densenet201 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/densenet201\n",
      "--- Finished extraction for model: densenet201 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4fc47b079544f479e9ff36d1ab5fee9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d94902df0c634bcca5e7ed415c35414c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: resnet34 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: resnet34 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/resnet34\n",
      "--- Finished extraction for model: resnet34 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6c2a8c9c770418c9a154d7053295806"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ed6d763479e40a68b961e8123af2e17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: resnet50 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: resnet50 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/resnet50\n",
      "--- Finished extraction for model: resnet50 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09f09019287a450b9707d6e4589ed22a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b181789042ae40be99e0565474a3a612"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: resnet101 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: resnet101 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/resnet101\n",
      "--- Finished extraction for model: resnet101 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1719c9c42c8940d68d27ebab265ec92e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b66489eef06e436586ac1574cb0fff2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: resnet152 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: resnet152 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4094 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/resnet152\n",
      "--- Finished extraction for model: resnet152 ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad3c17f60c224b7a99f00dc295c785af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40ab914a44e1462fa12eaf94a13f6de0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: googlenet on dataset: birdsnap ---\n",
      "--- Starting extraction for model: googlenet on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/googlenet\n",
      "--- Finished extraction for model: googlenet ---\n",
      "getting dataset\n",
      "Loading 'sasha/birdsnap' and creating label map...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/127 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9517fad6234f488f8e9d7e98c0d54140"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35570d18787f46deb261eb32a57a5d78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 500 unique classes.\n",
      "getting model\n",
      "Initializing DataLoader with 39860 samples.\n",
      "Initializing model: inception_v3 on dataset: birdsnap ---\n",
      "--- Starting extraction for model: inception_v3 on dataset: birdsnap ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Warning: Skipping corrupt image at index 9287: image file is truncated (45 bytes not processed)\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/birdsnap/inception_v3\n",
      "--- Finished extraction for model: inception_v3 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: mobilenet_v2 on dataset: imagenet ---\n",
      "--- Starting extraction for model: mobilenet_v2 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/mobilenet_v2\n",
      "--- Finished extraction for model: mobilenet_v2 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: mnasnet1_0 on dataset: imagenet ---\n",
      "--- Starting extraction for model: mnasnet1_0 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/mnasnet1_0\n",
      "--- Finished extraction for model: mnasnet1_0 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: densenet121 on dataset: imagenet ---\n",
      "--- Starting extraction for model: densenet121 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/densenet121\n",
      "--- Finished extraction for model: densenet121 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: densenet169 on dataset: imagenet ---\n",
      "--- Starting extraction for model: densenet169 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/densenet169\n",
      "--- Finished extraction for model: densenet169 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: densenet201 on dataset: imagenet ---\n",
      "--- Starting extraction for model: densenet201 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/densenet201\n",
      "--- Finished extraction for model: densenet201 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: resnet34 on dataset: imagenet ---\n",
      "--- Starting extraction for model: resnet34 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/resnet34\n",
      "--- Finished extraction for model: resnet34 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: resnet50 on dataset: imagenet ---\n",
      "--- Starting extraction for model: resnet50 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4094 finite bars.\n",
      "Saving results to: extraction_results/imagenet/resnet50\n",
      "--- Finished extraction for model: resnet50 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: resnet101 on dataset: imagenet ---\n",
      "--- Starting extraction for model: resnet101 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/resnet101\n",
      "--- Finished extraction for model: resnet101 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: resnet152 on dataset: imagenet ---\n",
      "--- Starting extraction for model: resnet152 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/resnet152\n",
      "--- Finished extraction for model: resnet152 ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: googlenet on dataset: imagenet ---\n",
      "--- Starting extraction for model: googlenet on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4095 finite bars.\n",
      "Saving results to: extraction_results/imagenet/googlenet\n",
      "--- Finished extraction for model: googlenet ---\n",
      "getting dataset\n",
      "Using pre-downloaded ImageNet from relative path...\n",
      "getting model\n",
      "getting targets\n",
      "splitting dataset into training and test sets\n",
      "Initializing DataLoader with 250000 samples.\n",
      "Initializing model: inception_v3 on dataset: imagenet ---\n",
      "--- Starting extraction for model: inception_v3 on dataset: imagenet ---\n",
      "Conducting features extraction...\n",
      "Registering embedding hook on layer: Linear\n",
      "Model instantiated, intializing forward pass\n",
      "Forward pass successful\n",
      "subsampling for persistent diagram\n",
      "computing persistent diagram\n",
      "Computing Persistence Diagram...\n",
      "Computed H0 persistence diagram with 4094 finite bars.\n",
      "Saving results to: extraction_results/imagenet/inception_v3\n",
      "--- Finished extraction for model: inception_v3 ---\n",
      "CPU times: user 1d 13h 8min 58s, sys: 24min 37s, total: 1d 13h 33min 35s\n",
      "Wall time: 12h 22min 55s\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:15:07.802349Z",
     "start_time": "2025-07-31T08:15:07.800840Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "5077e91bbb378d2f",
   "outputs": [],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
